---

## **4. Scale or Kill Exercise (3:00pm - 4:00pm)**

**Three Case Studies to Print** (3 pages total - 1 per case)

---

**CASE STUDY A: The Clear Success**

**AI Inventory Prediction System - Fashion Retailer**

**The Project:**
- AI predicts demand for clothing items by store
- Uses historical sales, weather, local events, social media trends
- Automatically adjusts stock orders

**Timeline:** 12-month pilot across 10 stores

**Investment:**
- Development: $180K
- Implementation: $45K
- Training: $15K
- **Total: $240K**

**Results After 12 Months:**

**Inventory Metrics:**
- Stock-outs reduced: 45% → 12% (down 73%)
- Overstock reduced: 31% → 9% (down 71%)
- Inventory turnover: 4.2x → 6.8x (up 62%)
- Waste from unsold seasonal items: Down 58%

**Financial Impact:**
- Revenue increase (fewer stock-outs): +$1.2M annually
- Cost savings (less overstock): +$800K annually
- **Total benefit: $2M annually**
- **ROI: 733% (first year)**

**Operational:**
- Store managers love it ("finally get the right products")

- Ordering process time reduced by 70%
- Freed up 15 hours/week for merchandising team to focus on strategy

**Customer Impact:**
- Customer satisfaction up 14% (products in stock when they want them)
- Fewer disappointed customers leaving empty-handed

**Technical Performance:**
- Prediction accuracy: 87% (vs. 62% with old manual forecasting)
- System uptime: 99.7%
- Integration with existing systems: Seamless

**Challenges Encountered:**
- Initial 2 months had accuracy issues (training data needed refinement)
- One store manager resisted for 3 months (eventually became biggest advocate)
- IT needed to upgrade server capacity (unexpected $12K cost)

**Current Status:**
- All 10 pilot stores want to keep it
- 15 other stores requesting access
- Merchandising VP champions it in every meeting

**Team Recommendation:** Scale to all 50 stores

---

**YOUR ANALYSIS:**

**Decision:** ☐ Scale  ☐ Pivot  ☐ Kill

**Rationale:**

**If SCALE, answer:**
- Rollout timeline:
- Additional investment needed:
- Key risks to manage:
- Success criteria for full rollout:

**Questions you still have:**

---

**CASE STUDY B: The Clear Failure**

**AI-Powered Staff Scheduling System - Restaurant Chain**

**The Project:**
- AI creates optimal staff schedules based on predicted customer traffic
- Factors in: historical patterns, weather, local events, holidays, staff availability
- Goal: Reduce labor costs while maintaining service quality

**Timeline:** 6-month pilot across 8 restaurants

**Investment:**
- Software license: $95K
- Implementation: $60K
- Training: $25K
- **Total: $180K**

**Results After 6 Months:**

**Labor Metrics:**
- Labor cost as % of revenue: 28% → 26% (down 2% - target met!)
- Staff hours per week: 2,840 → 2,520 (down 11%)
- **But...**

**Service Impact:**
- Customer wait times: 8 minutes → 18 minutes (up 125%)
- Customer complaints: Up 340%
- Table turnover rate: Down 22%
- Customer satisfaction: 82% → 61% (down 21 points)

**Staff Impact:**
- Employee turnover: 23% annually → 67% annually (nearly tripled)
- Staff satisfaction survey: 68% → 31%
- Shifts scheduled with <24hrs notice: Up 450%
- Split shifts assigned: Up 280%
- Staff calling in sick: Up 78% (suspected protest/burnout)

**What Went Wrong:**

The AI optimized for labor cost reduction, creating:
- **Unpredictable schedules** (staff couldn't plan their lives)
- **Chronic understaffing** during unexpected rushes
- **Split shifts** (work 11am-2pm, come back 6pm-9pm) that staff hated
- **Zero consideration for employee wellbeing**

**Example:**
- AI scheduled 3 servers for Saturday dinner (historically needed 5)
- Saved $240 in labor that night
- Restaurant was slammed, terrible service, lost $1,800 in walkouts
- 2 servers quit the next week

**Financial Reality Check:**
- Labor savings: $84K over 6 months
- Revenue loss (slower table turns, walkouts): $127K
- Recruiting/training costs (high turnover): $93K
- **Net impact: -$136K loss**

**Stakeholder Feedback:**
- Restaurant managers: "This is a disaster. It's destroying morale."
- Staff: "I have two jobs. I can't work when the AI changes my schedule with 12 hours notice."
- District manager: "We're saving money but losing customers. Not worth it."
- HR: "We're hemorrhaging good people."

**Technical Performance:**
- Algorithm worked as designed (reduced labor costs ✓)
- System uptime: 98%
- Integration: Fine

**The Real Problem:** 
Wrong optimization target. AI did what it was told (minimize labor cost) but ignored human/business consequences.

**Current Status:**
- 6 of 8 restaurants want to stop using it
- 2 managers already reverted to manual scheduling
- Multiple formal complaints filed

**Team Recommendation:** Kill the project

---

**YOUR ANALYSIS:**

**Decision:** ☐ Scale  ☐ Pivot  ☐ Kill

**Rationale:**

**If KILL, answer:**
- Key lesson learned:
- What would you do differently next time:
- How do you communicate this to stakeholders:

**If PIVOT, answer:**
- What would you change:
- Would that address the core issues:

---

**CASE STUDY C: The Ambiguous One**

**AI Dynamic Pricing System - E-Commerce Platform**

**The Project:**
- AI adjusts product prices in real-time based on demand, competitor pricing, inventory levels, customer browsing behavior
- Goal: Maximize revenue while staying competitive
- Prices can fluctuate throughout the day

**Timeline:** 9-month pilot on 500 products (out of 12,000 total)

**Investment:**
- Development: $220K
- Implementation: $45K
- A/B testing infrastructure: $35K
- **Total: $300K**

**Results After 9 Months:**

**Revenue Metrics:**
- Revenue on pilot products: +8.2% vs. control group
- Gross margin: +3.1%
- Conversion rate: -2.4% (slightly down)
- Average order value: +11.7%

**Financial Impact:**
- Additional revenue: +$890K (annualized: ~$1.2M)
- Additional margin: +$312K (annualized: ~$415K)
- **ROI: 138% (first year, if sustained)**

**Looks good, right? But...**

**Customer Experience Metrics:**
- Customer complaints about pricing: +340%
- Social media mentions (negative): +520%
- Cart abandonment: 58% → 71% (up 13 points)
- Customer satisfaction: 79% → 67% (down 12 points)
- Return rate: 12% → 18% (up 50%)

**What's Happening:**

**Scenario 1: The "Price Watcher"**
- Customer browses a product ($89.99)
- Leaves site, comes back 2 hours later
- Price is now $107.99 (+20%)
- Customer feels manipulated, abandons cart
- Posts angry review: "They're tracking me and raising prices!"

**Scenario 2: The "Bad Luck Shopper"**
- Customer A buys item Monday morning: $79.99
- Customer B (their friend) buys same item Tuesday afternoon: $64.99
- Customer A finds out, feels ripped off
- Demands price match, returns item, writes negative review

**Scenario 3: The "Algorithm Winner"**
- Item usually $150, AI drops to $112 during low-demand period
- Customer thrilled, tells friends
- Friends try to buy, price is back to $145
- Brand looks inconsistent/untrustworthy

**Qualitative Feedback:**

**Positive:**
- "I got an amazing deal on exactly what I needed" (15% of comments)
- Revenue is measurably up
- Clearing slow-moving inventory faster

**Negative:**
- "Predatory pricing - they're tracking me!" (43% of comments)
- "Prices change every time I look - can't trust them" (28%)
- "My friend paid less for the same thing - that's not fair" (31%)
- Brand perception: "Opportunistic," "Manipulative," "Can't trust them"

**Media Attention:**
- Local news picked up story: "Retailer Uses AI to Charge Different Customers Different Prices"
- Article was technically inaccurate (AI adjusts by time/demand, not by customer) but damage done

**Internal Stakeholder Views:**

**CFO:** "Revenue is up. This works. Scale it."

**CMO:** "Brand trust is down. Customer lifetime value will suffer. This is short-term thinking."

**Head of E-commerce:** "The data shows it's working. Negative sentiment is from a vocal minority."

**Customer Service:** "We're drowning in pricing complaints. This is creating massive operational burden."

**CEO:** "I need a recommendation. Is this good for the business long-term?"

**Technical Performance:**
- Algorithm performs as expected
- 99.2% uptime
- Pricing adjustments smooth and accurate

**The Dilemma:**

✅ **Financially successful** (8.2% revenue increase, positive ROI)  
❌ **Customer experience suffering** (satisfaction down 12 points)

❓ **Long-term impact unclear:**
- Will revenue gains sustain if brand trust erodes?
- Are we winning revenue today but losing loyalty tomorrow?
- Is 8% revenue gain worth 12-point satisfaction drop?

**Market Context:**
- Competitors doing similar things (Amazon, airlines)
- But some competitors explicitly market "no surprise pricing" as differentiator
- Regulatory scrutiny on dynamic pricing increasing

**Current Status:**
- Finance wants to scale
- Marketing wants to kill
- CEO wants your recommendation

---

**YOUR ANALYSIS (This is the hard one):**

**Decision:** ☐ Scale  ☐ Pivot  ☐ Kill

**Rationale:**

**Risk Assessment:**

| Scenario | If SCALE | If PIVOT | If KILL |
|----------|----------|----------|---------|
| Best Case | | | |
| Worst Case | | | |
| Most Likely | | | |

**Your Recommendation:**

**Implementation Plan:**

**How you'll defend this decision to:**
- **CFO (wants scale):**

- **CMO (wants kill):**

- **CEO (wants clarity):**

**Success Metrics to Monitor:**

---

### **Decision Framework Reference Sheet** (1 page - all participants)

Print this as a standalone reference they can keep.

---

**AI PROJECT DECISION FRAMEWORK**

**When evaluating whether to Scale, Pivot, or Kill an AI pilot:**

---

## **SCALE IT - When:**

**Financial:**
- ✅ Clear, measurable ROI (typically >200% for first year)
- ✅ Benefits exceed costs by significant margin
- ✅ Costs to scale are predictable and manageable

**Technical:**
- ✅ System performs reliably (>95% uptime)
- ✅ Accuracy meets or exceeds targets consistently
- ✅ Technical debt is manageable
- ✅ Can integrate with existing systems

**Organizational:**
- ✅ Stakeholders actively support it
- ✅ End users want to keep using it
- ✅ Clear ownership and maintenance plan
- ✅ Team has capability to support at scale

**Customer/User:**
- ✅ Positive impact on customer/employee experience
- ✅ Satisfaction metrics improving or stable
- ✅ No significant ethical concerns

**Strategic:**
- ✅ Aligns with business strategy
- ✅ Creates competitive advantage
- ✅ Scalable without major redesign

**Red Flags to Watch Even When Scaling:**
- Vocal minority of strong opposition
- Success dependent on one person
- Unclear what happens at 10x volume

---

## **PIVOT IT - When:**

**Core concept has merit but execution needs adjustment:**

**Pivot Scenarios:**

**1. Wrong Scope Pivot**
- Problem: Too ambitious or too narrow
- Example: Tried to automate all queries → Pivot to automating just order tracking
- Action: Narrow or expand scope

**2. Wrong Metric Pivot**
- Problem: Optimizing for wrong outcome
- Example: AI reduced labor costs but destroyed service quality
- Action: Change success criteria and retrain

**3. Wrong Audience Pivot**
- Problem: Built for wrong users
- Example: Built for executives, but frontline staff need it more
- Action: Redesign for different user

**4. Wrong Approach Pivot**
- Problem: Technical approach is flawed
- Example: AI makes decisions → Pivot to AI suggests, human decides
- Action: Change human-AI interaction model

**5. Wrong Timing Pivot**
- Problem: Organization/market not ready
- Example: Data quality issues need fixing first
- Action: Pause, fix prerequisites, relaunch

**When to Pivot vs. Kill:**
- Pivot: Core value proposition is sound, execution is fixable
- Kill: Fundamental concept is flawed

---

## **KILL IT - When:**

**Financial:**
- ❌ ROI is negative or marginal with no path to improvement
- ❌ Costs exceed benefits even in best-case scenario
- ❌ Opportunity cost too high (resources better used elsewhere)

**Technical:**
- ❌ Fundamental technical limitations can't be overcome
- ❌ "It just doesn't work" despite multiple attempts
- ❌ Technical debt is unmanageable

**Organizational:**
- ❌ Widespread resistance that won't budge
- ❌ Creating more problems than it solves
- ❌ No one wants to own/maintain it
- ❌ Key sponsor left/withdrawn support

**Customer/User:**
- ❌ Actively harming customer experience
- ❌ Significant ethical issues identified
- ❌ Brand/trust damage occurring
- ❌ Regulatory risks too high

**Strategic:**
- ❌ No longer aligns with business direction
- ❌ Competitor solved this better/cheaper
- ❌ Market has moved on
- ❌ Wrong problem to solve

**When Killing is the Right Answer:**
- You're throwing good money after bad
- Sunk cost fallacy is driving decisions
- "We've come too far to quit" is the main argument
- Everyone's relieved when you suggest killing it

**How to Kill Gracefully:**
- Document lessons learned
- Celebrate team effort (they tried)
- Extract reusable components
- Communicate clearly why
- Don't punish the team for intelligent failure

---

## **THE HARD QUESTIONS:**

Ask yourself these before deciding:

**1. The Honesty Test:**
- "If I were starting from zero today, would I launch this?"
- If no → Consider killing

**2. The Resource Test:**
- "What else could we do with these people/budget?"
- If answer is more compelling → Consider pivoting or killing

**3. The Founder Test:**
- "If this were my money, would I invest more?"
- If no → Red flag

**4. The Reputation Test:**
- "If this fails publicly at scale, what happens?"
- If answer is catastrophic → Don't scale yet

**5. The Grandmother Test:**
- "Can I explain why this is good for customers to my grandmother?"
- If you're doing mental gymnastics → Ethical issue

**6. The Year Test:**
- "Will I be proud of this decision in a year?"
- If unsure → Gather more data

---

## **COMMON DECISION TRAPS:**

**❌ Sunk Cost Fallacy**
- "We've already spent $300K, we can't quit now"
- Fix: Judge only by future costs vs. future benefits

**❌ Metric Fixation**
- "ROI is positive, so scale it"
- Fix: Look at broader impact (customer satisfaction, employee morale, brand)

**❌ Hope-Based Planning**
- "Problems will work themselves out at scale"
- Fix: Problems typically get worse at scale, not better

**❌ Perfection Paralysis**
- "Let's wait until it's perfect"
- Fix: 80% good with momentum beats 95% good that's late

**❌ Executive Pressure**
- "CEO wants this, so we must scale"
- Fix: Your job is to give honest recommendations, not tell them what they want to hear

**❌ Personal Investment**
- "I've worked on this for a year, it must work"
- Fix: Separate ego from outcome

---

**Remember:** 
- **Killing a bad project is success, not failure**
- **Pivoting shows learning, not weakness**
- **Scaling the wrong thing is the biggest mistake**

---

## **CLOSING REFLECTION TEMPLATE** (1 page per participant)

Print for everyone to complete at end of day (3:45pm - 4:25pm)

---

**AI IN LEADERSHIP & PROJECT MANAGEMENT**
**Personal Reflection & Action Plan**

**Name:** _________________ **Date:** _________________

**Organization:** _________________ **Role:** _________________

---

### **PART 1: Key Insights (10 minutes)**

**What was your biggest "aha moment" today?**

**What surprised you most?**

**What challenged your assumptions?**

---

### **PART 2: Application to Your Context (15 minutes)**

**Current or upcoming AI project you're working on:**

**How does what you learned today apply?**

**Specific stakeholders you need to manage differently:**

| Stakeholder | Their Concerns (that you now understand better) | Your New Engagement Strategy |
|-------------|------------------------------------------------|------------------------------|
| | | |
| | | |
| | | |

**Biggest risk you're now aware of:**

**How you'll mitigate it:**

---

### **PART 3: Action Plan (10 minutes)**

**Three things you'll do differently starting Monday:**

**1. THIS WEEK (immediate action):**

**Success looks like:**

**2. THIS MONTH (short-term improvement):**

**Success looks like:**

**3. THIS QUARTER (strategic change):**

**Success looks like:**

---

### **PART 4: Resources & Support**

**What additional knowledge/skills do you need?**

**Who can help you?**

**What obstacles do you anticipate?**

**How will you overcome them?**

---

### **PART 5: Commitment**

**The ONE thing I commit to doing as a result of today:**

**I will do this by (date):** _________________

**I will know I've succeeded when:**

**I will share progress with:** _________________

---

**Optional: Share with facilitator**

☐ I'm willing to be contacted for follow-up on how this worked out

Email: _________________

---

## **FACILITATOR MATERIALS** (Not for participants)

### **Facilitator Guide Overview** (5 pages)

I'll create a separate detailed facilitator guide, but here's what it includes:

**For Each Exercise:**
1. **Setup** (5 min before)
   - Materials needed
   - Room arrangement
   - What to prepare

2. **Introduction** (2-3 min)
   - What you say to frame it
   - Why this matters
   - Expected outcomes

3. **During Exercise**
   - What to watch for
   - When to intervene (and when not to)
   - Coaching questions to ask groups
   - Common mistakes groups make

4. **Debrief Questions**
   - What to ask the room
   - How to extract insights
   - Key learning points to reinforce

5. **Timing Cues**
   - "5 minutes left" warning
   - When to move on even if not finished

6. **Backup Plans**
   - If exercise finishes early
   - If exercise runs long
   - If it's not working

---

## **SUMMARY: Complete Print List**

### **Per Participant Packet (15-20 pages):**
1. Stakeholder Speed Dating - Workbook page (1 page)
2. Pilot Scoping - Case study + Worksheet (2 pages)
3. Crisis Simulation - Overview + 4 crisis scenarios (6 pages)
4. Scale or Kill - 3 case studies (3 pages)
5. Decision Framework Reference (1 page)
6. Personal Reflection Template (1 page)
**Total: ~14 pages per participant × 25 participants = 350 pages**
