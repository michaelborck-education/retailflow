# AI PROJECT DECISION FRAMEWORK
## Reference Sheet - Keep This Handy

When evaluating whether to **SCALE**, **PIVOT**, or **KILL** an AI pilot project:

---

## ✅ SCALE IT - When You See:

### Financial Indicators:
- ✅ Clear, measurable ROI (typically >200% for first year)
- ✅ Benefits exceed costs by significant margin  
- ✅ Costs to scale are predictable and manageable
- ✅ Business case strengthens at scale (economies of scale)

### Technical Performance:
- ✅ System performs reliably (>95% uptime)
- ✅ Accuracy meets or exceeds targets consistently
- ✅ Technical debt is manageable
- ✅ Can integrate with existing systems without major refactoring
- ✅ Maintenance requirements are sustainable

### Organizational Readiness:
- ✅ Stakeholders actively support and champion it
- ✅ End users want to keep using it (not just tolerating it)
- ✅ Clear ownership and maintenance plan exists
- ✅ Team has capability to support at scale
- ✅ Change management has been successful

### Customer/User Impact:
- ✅ Positive impact on customer or employee experience
- ✅ Satisfaction metrics improving or stable
- ✅ No significant ethical concerns or unintended consequences
- ✅ Complaints are minor and manageable

### Strategic Alignment:
- ✅ Aligns with long-term business strategy
- ✅ Creates sustainable competitive advantage
- ✅ Scalable without major redesign
- ✅ Addresses a real business problem (not just "AI for AI's sake")

### Red Flags to Watch Even When Scaling:
- ⚠️ Vocal minority with strong opposition (may indicate larger issues)
- ⚠️ Success depends heavily on one person or team
- ⚠️ Unclear what happens at 10x volume or usage
- ⚠️ Brittle integration with other systems
- ⚠️ Hidden dependencies or technical debt

---

## 🔄 PIVOT IT - When You Need To:

**Core concept has merit, but execution needs adjustment.**

### Common Pivot Scenarios:

#### 1. **Wrong Scope Pivot**
**Problem:** Too ambitious or too narrow to prove value

**Example:** Tried to automate all customer queries → Pivot to automating just order tracking

**Action:** Narrow scope to winnable subset OR expand to capture enough value

---

#### 2. **Wrong Metric Pivot**
**Problem:** Optimizing for the wrong outcome, creating unintended consequences

**Example:** AI reduced labor costs but destroyed service quality and morale

**Action:** Change success criteria and retrain model with new objectives

---

#### 3. **Wrong Audience Pivot**
**Problem:** Built for the wrong users or use case

**Example:** Built AI assistant for executives, but frontline staff need it more

**Action:** Redesign for different user group or use case

---

#### 4. **Wrong Approach Pivot**
**Problem:** Technical approach or human-AI interaction model is flawed

**Examples:**
- AI makes autonomous decisions → Pivot to AI suggests, human decides
- Batch processing → Pivot to real-time  
- Fully automated → Pivot to augmented/assisted

**Action:** Change the fundamental interaction model

---

#### 5. **Wrong Timing Pivot**
**Problem:** Organization or market not ready, prerequisites missing

**Examples:**
- Data quality issues need fixing first
- Team needs training before adoption
- Market regulation pending

**Action:** Pause, fix prerequisites, relaunch when ready

---

### Pivot vs. Kill Decision:

**PIVOT when:**
- Core value proposition is sound
- Problems are fixable with reasonable effort
- Stakeholders still believe in the potential
- Learning justifies continued investment

**KILL when:**
- Fundamental concept is flawed
- Fixes would require starting over anyway
- Stakeholders have lost faith
- Better opportunities exist for the resources

---

## ❌ KILL IT - When You Must:

### Financial Red Flags:
- ❌ ROI is negative or marginal with no realistic path to improvement
- ❌ Costs exceed benefits even in best-case scenarios
- ❌ Opportunity cost too high (resources better used elsewhere)
- ❌ Diminishing returns with more investment

### Technical Blockers:
- ❌ Fundamental technical limitations that can't be overcome
- ❌ "It just doesn't work" despite multiple attempts to fix
- ❌ Technical debt is unmanageable or growing
- ❌ Required accuracy/performance is unachievable with current technology

### Organizational Resistance:
- ❌ Widespread, persistent resistance that won't budge
- ❌ Creating more problems than it solves
- ❌ No one wants to own or maintain it
- ❌ Key sponsor has left or withdrawn support
- ❌ Political damage outweighs potential benefits

### Customer/User Harm:
- ❌ Actively harming customer or employee experience
- ❌ Significant ethical issues identified that can't be mitigated
- ❌ Brand or trust damage occurring
- ❌ Regulatory or legal risks are too high
- ❌ Safety concerns

### Strategic Misalignment:
- ❌ No longer aligns with business direction
- ❌ Competitor has solved this better/cheaper (can't catch up)
- ❌ Market has moved on or problem is no longer relevant
- ❌ Wrong problem to solve (addressing symptom, not cause)

---

## When Killing is the RIGHT Answer:

Remember: **Killing a bad project is success, not failure.**

**You should kill when:**
- You're throwing good money after bad
- Sunk cost fallacy is driving decisions ("we've invested too much to quit")
- "We've come too far to stop now" is the main argument
- Everyone is secretly relieved when you suggest killing it
- You're scaling problems instead of solutions

---

## How to Kill Gracefully:

1. **Document lessons learned** comprehensively
2. **Celebrate the team's effort** (they tried, learned valuable insights)
3. **Extract reusable components** (code, data, knowledge)
4. **Communicate clearly** why you're killing it
5. **Don't punish the team** for intelligent failure
6. **Share insights** so others learn from this

**Frame it as:** "We learned this doesn't work, which is valuable. Now we can invest in what does work."

---

## THE CRITICAL QUESTIONS

Ask yourself these before making a decision:

### 1. **The Honesty Test**
*"If I were starting from zero today, knowing what I know now, would I launch this project?"*

- If NO → Strong signal to KILL
- If MAYBE → Consider PIVOT  
- If YES → Consider SCALE

---

### 2. **The Resource Test**
*"What else could we do with these people, budget, and time?"*

- If answer is more compelling than current project → KILL or PIVOT
- If this is still the best use → SCALE

---

### 3. **The Founder Test**
*"If this were my personal money, would I invest more?"*

- If NO → Why are you investing company money?
- If YES → You believe in it

---

### 4. **The Reputation Test**
*"If this fails publicly at scale, what happens to the company/brand/team?"*

- If catastrophic → Don't scale yet (or ever)
- If manageable → Consider the risk

---

### 5. **The Grandmother Test**
*"Can I explain why this is good for customers to my grandmother in simple terms?"*

- If you're doing mental gymnastics → Ethical red flag
- If explanation is straightforward → Probably sound

---

### 6. **The Time Test**
*"Will I be proud of this decision in one year? In five years?"*

- If unsure → Gather more data or reconsider
- If confident → Proceed

---

### 7. **The Stakeholder Test**
*"Can I defend this decision to all stakeholders: customers, employees, shareholders, regulators?"*

- If NO to any critical stakeholder → Reconsider
- If YES to all → Strong foundation

---

## COMMON DECISION TRAPS TO AVOID

### ❌ Sunk Cost Fallacy
**Trap:** "We've already spent $300K, we can't quit now"

**Fix:** Judge only by future costs vs. future benefits. Past spending is gone regardless.

---

### ❌ Metric Fixation
**Trap:** "ROI is positive, so we must scale it"

**Fix:** Look at broader impact - customer satisfaction, employee morale, brand equity, long-term effects

---

### ❌ Hope-Based Planning
**Trap:** "These problems will work themselves out at scale"

**Reality:** Problems typically get WORSE at scale, not better

**Fix:** Assume current problems will amplify 10x

---

### ❌ Perfection Paralysis
**Trap:** "Let's wait until it's perfect before scaling"

**Fix:** 80% good with momentum often beats 95% good that's late. Perfect is the enemy of good.

---

### ❌ Executive Pressure
**Trap:** "CEO wants this, so we must scale regardless of evidence"

**Fix:** Your job is honest recommendations, not telling leaders what they want to hear

---

### ❌ Personal Investment
**Trap:** "I've worked on this for a year, my ego is attached, it must succeed"

**Fix:** Separate your ego from outcomes. Killing bad projects is wise leadership.

---

### ❌ Confirmation Bias
**Trap:** "I'll focus on the positive data and ignore warning signs"

**Fix:** Actively seek disconfirming evidence. What would prove you wrong?

---

### ❌ Groupthink
**Trap:** "Everyone agrees we should scale, so it must be right"

**Fix:** Assign someone to play devil's advocate. Seek diverse perspectives.

---

## REMEMBER

### Three Core Principles:

1. **Killing a bad project is success, not failure**
   - It frees resources for better opportunities
   - It demonstrates good judgment
   - It protects the organization

2. **Pivoting shows learning, not weakness**
   - Adapting to evidence is smart
   - Stubborn persistence can be dangerous
   - Flexibility is strength

3. **Scaling the wrong thing is the biggest mistake**
   - Amplifies problems 10x
   - Harder to unwind once at scale
   - Damages credibility for future AI initiatives

---

## FINAL WISDOM

> "The cost of being wrong about scaling is much higher than the cost of being wrong about killing."

> "When in doubt, run another small experiment rather than scaling prematurely."

> "Data-driven decisions are good. Values-driven decisions are essential. Best decisions combine both."

---

**Use this framework, but remember:**  
Judgment, context, and values matter as much as metrics. There's rarely a perfect answer, but there's always a defensible decision based on clear reasoning.

---

*Keep this reference sheet. Use it for every AI project decision you face.*