# AI PROJECT DECISION FRAMEWORK
## Reference Sheet - Keep This Handy

When evaluating whether to **SCALE**, **PIVOT**, or **KILL** an AI pilot project:

---

## âœ… SCALE IT - When You See:

### Financial Indicators:
- âœ… Clear, measurable ROI (typically >200% for first year)
- âœ… Benefits exceed costs by significant margin  
- âœ… Costs to scale are predictable and manageable
- âœ… Business case strengthens at scale (economies of scale)

### Technical Performance:
- âœ… System performs reliably (>95% uptime)
- âœ… Accuracy meets or exceeds targets consistently
- âœ… Technical debt is manageable
- âœ… Can integrate with existing systems without major refactoring
- âœ… Maintenance requirements are sustainable

### Organizational Readiness:
- âœ… Stakeholders actively support and champion it
- âœ… End users want to keep using it (not just tolerating it)
- âœ… Clear ownership and maintenance plan exists
- âœ… Team has capability to support at scale
- âœ… Change management has been successful

### Customer/User Impact:
- âœ… Positive impact on customer or employee experience
- âœ… Satisfaction metrics improving or stable
- âœ… No significant ethical concerns or unintended consequences
- âœ… Complaints are minor and manageable

### Strategic Alignment:
- âœ… Aligns with long-term business strategy
- âœ… Creates sustainable competitive advantage
- âœ… Scalable without major redesign
- âœ… Addresses a real business problem (not just "AI for AI's sake")

### Red Flags to Watch Even When Scaling:
- âš ï¸ Vocal minority with strong opposition (may indicate larger issues)
- âš ï¸ Success depends heavily on one person or team
- âš ï¸ Unclear what happens at 10x volume or usage
- âš ï¸ Brittle integration with other systems
- âš ï¸ Hidden dependencies or technical debt

---

## ðŸ”„ PIVOT IT - When You Need To:

**Core concept has merit, but execution needs adjustment.**

### Common Pivot Scenarios:

#### 1. **Wrong Scope Pivot**
**Problem:** Too ambitious or too narrow to prove value

**Example:** Tried to automate all customer queries â†’ Pivot to automating just order tracking

**Action:** Narrow scope to winnable subset OR expand to capture enough value

---

#### 2. **Wrong Metric Pivot**
**Problem:** Optimizing for the wrong outcome, creating unintended consequences

**Example:** AI reduced labor costs but destroyed service quality and morale

**Action:** Change success criteria and retrain model with new objectives

---

#### 3. **Wrong Audience Pivot**
**Problem:** Built for the wrong users or use case

**Example:** Built AI assistant for executives, but frontline staff need it more

**Action:** Redesign for different user group or use case

---

#### 4. **Wrong Approach Pivot**
**Problem:** Technical approach or human-AI interaction model is flawed

**Examples:**
- AI makes autonomous decisions â†’ Pivot to AI suggests, human decides
- Batch processing â†’ Pivot to real-time  
- Fully automated â†’ Pivot to augmented/assisted

**Action:** Change the fundamental interaction model

---

#### 5. **Wrong Timing Pivot**
**Problem:** Organization or market not ready, prerequisites missing

**Examples:**
- Data quality issues need fixing first
- Team needs training before adoption
- Market regulation pending

**Action:** Pause, fix prerequisites, relaunch when ready

---

### Pivot vs. Kill Decision:

**PIVOT when:**
- Core value proposition is sound
- Problems are fixable with reasonable effort
- Stakeholders still believe in the potential
- Learning justifies continued investment

**KILL when:**
- Fundamental concept is flawed
- Fixes would require starting over anyway
- Stakeholders have lost faith
- Better opportunities exist for the resources

---

## âŒ KILL IT - When You Must:

### Financial Red Flags:
- âŒ ROI is negative or marginal with no realistic path to improvement
- âŒ Costs exceed benefits even in best-case scenarios
- âŒ Opportunity cost too high (resources better used elsewhere)
- âŒ Diminishing returns with more investment

### Technical Blockers:
- âŒ Fundamental technical limitations that can't be overcome
- âŒ "It just doesn't work" despite multiple attempts to fix
- âŒ Technical debt is unmanageable or growing
- âŒ Required accuracy/performance is unachievable with current technology

### Organizational Resistance:
- âŒ Widespread, persistent resistance that won't budge
- âŒ Creating more problems than it solves
- âŒ No one wants to own or maintain it
- âŒ Key sponsor has left or withdrawn support
- âŒ Political damage outweighs potential benefits

### Customer/User Harm:
- âŒ Actively harming customer or employee experience
- âŒ Significant ethical issues identified that can't be mitigated
- âŒ Brand or trust damage occurring
- âŒ Regulatory or legal risks are too high
- âŒ Safety concerns

### Strategic Misalignment:
- âŒ No longer aligns with business direction
- âŒ Competitor has solved this better/cheaper (can't catch up)
- âŒ Market has moved on or problem is no longer relevant
- âŒ Wrong problem to solve (addressing symptom, not cause)

---

## When Killing is the RIGHT Answer:

Remember: **Killing a bad project is success, not failure.**

**You should kill when:**
- You're throwing good money after bad
- Sunk cost fallacy is driving decisions ("we've invested too much to quit")
- "We've come too far to stop now" is the main argument
- Everyone is secretly relieved when you suggest killing it
- You're scaling problems instead of solutions

---

## How to Kill Gracefully:

1. **Document lessons learned** comprehensively
2. **Celebrate the team's effort** (they tried, learned valuable insights)
3. **Extract reusable components** (code, data, knowledge)
4. **Communicate clearly** why you're killing it
5. **Don't punish the team** for intelligent failure
6. **Share insights** so others learn from this

**Frame it as:** "We learned this doesn't work, which is valuable. Now we can invest in what does work."

---

## THE CRITICAL QUESTIONS

Ask yourself these before making a decision:

### 1. **The Honesty Test**
*"If I were starting from zero today, knowing what I know now, would I launch this project?"*

- If NO â†’ Strong signal to KILL
- If MAYBE â†’ Consider PIVOT  
- If YES â†’ Consider SCALE

---

### 2. **The Resource Test**
*"What else could we do with these people, budget, and time?"*

- If answer is more compelling than current project â†’ KILL or PIVOT
- If this is still the best use â†’ SCALE

---

### 3. **The Founder Test**
*"If this were my personal money, would I invest more?"*

- If NO â†’ Why are you investing company money?
- If YES â†’ You believe in it

---

### 4. **The Reputation Test**
*"If this fails publicly at scale, what happens to the company/brand/team?"*

- If catastrophic â†’ Don't scale yet (or ever)
- If manageable â†’ Consider the risk

---

### 5. **The Grandmother Test**
*"Can I explain why this is good for customers to my grandmother in simple terms?"*

- If you're doing mental gymnastics â†’ Ethical red flag
- If explanation is straightforward â†’ Probably sound

---

### 6. **The Time Test**
*"Will I be proud of this decision in one year? In five years?"*

- If unsure â†’ Gather more data or reconsider
- If confident â†’ Proceed

---

### 7. **The Stakeholder Test**
*"Can I defend this decision to all stakeholders: customers, employees, shareholders, regulators?"*

- If NO to any critical stakeholder â†’ Reconsider
- If YES to all â†’ Strong foundation

---

## COMMON DECISION TRAPS TO AVOID

### âŒ Sunk Cost Fallacy
**Trap:** "We've already spent $300K, we can't quit now"

**Fix:** Judge only by future costs vs. future benefits. Past spending is gone regardless.

---

### âŒ Metric Fixation
**Trap:** "ROI is positive, so we must scale it"

**Fix:** Look at broader impact - customer satisfaction, employee morale, brand equity, long-term effects

---

### âŒ Hope-Based Planning
**Trap:** "These problems will work themselves out at scale"

**Reality:** Problems typically get WORSE at scale, not better

**Fix:** Assume current problems will amplify 10x

---

### âŒ Perfection Paralysis
**Trap:** "Let's wait until it's perfect before scaling"

**Fix:** 80% good with momentum often beats 95% good that's late. Perfect is the enemy of good.

---

### âŒ Executive Pressure
**Trap:** "CEO wants this, so we must scale regardless of evidence"

**Fix:** Your job is honest recommendations, not telling leaders what they want to hear

---

### âŒ Personal Investment
**Trap:** "I've worked on this for a year, my ego is attached, it must succeed"

**Fix:** Separate your ego from outcomes. Killing bad projects is wise leadership.

---

### âŒ Confirmation Bias
**Trap:** "I'll focus on the positive data and ignore warning signs"

**Fix:** Actively seek disconfirming evidence. What would prove you wrong?

---

### âŒ Groupthink
**Trap:** "Everyone agrees we should scale, so it must be right"

**Fix:** Assign someone to play devil's advocate. Seek diverse perspectives.

---

## REMEMBER

### Three Core Principles:

1. **Killing a bad project is success, not failure**
   - It frees resources for better opportunities
   - It demonstrates good judgment
   - It protects the organization

2. **Pivoting shows learning, not weakness**
   - Adapting to evidence is smart
   - Stubborn persistence can be dangerous
   - Flexibility is strength

3. **Scaling the wrong thing is the biggest mistake**
   - Amplifies problems 10x
   - Harder to unwind once at scale
   - Damages credibility for future AI initiatives

---

## FINAL WISDOM

> "The cost of being wrong about scaling is much higher than the cost of being wrong about killing."

> "When in doubt, run another small experiment rather than scaling prematurely."

> "Data-driven decisions are good. Values-driven decisions are essential. Best decisions combine both."

---

**Use this framework, but remember:**  
Judgment, context, and values matter as much as metrics. There's rarely a perfect answer, but there's always a defensible decision based on clear reasoning.

---

*Keep this reference sheet. Use it for every AI project decision you face.*